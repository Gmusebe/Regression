# Linear Regression
# _________________________________________________
# I sought to predict sales using variable Tv from the Advertisement data.
# Load libraries
library(MASS)
library(ISLR)
library(dplyr)
library(tidyverse)
library(ggpubr)
theme_set(theme_pubr())
# Import data
path = "http://faculty.marshall.usc.edu/gareth-james/ISL/Advertising.csv"
data <- read.csv(path, header = TRUE, na.strings = "?")
attach(data)
# View the data
sample_n(data, 4)
# Drop the column "X" as it matches the index of the table.
data = data[, -1]
# Check for any missing data
length(which(is.na(data) == TRUE))
visdat::vis_dat(data) # no missing data
# Visualization
ggplot(data, aes(x = TV, y = sales)) +
geom_point() +
stat_smooth(colour = "red") +
ggtitle("TV vs SALES") + font("title", size = 29) +
ylab("Sales") + font("ylab", size = 20) +
xlab("TV Advertisement Budget(000)") + font("xlab", size = 20)
# The graph above suggests a linearly increasing relationship between the sales and the TV advertising budget variables
# Simple correlation.
cor(sales, TV) # =  0.7822244:
# It is right to strongly believe an increase in TV advertisement budget will result to an increase in Sales
# ________________________________________________________
# Simple Linear Regression
# ________________________________________________________
# The simple linear regression is used to predict a quantitative outcome y(sales) on the basis of one single predictor variable x(TV).
# Assumption: There is approximately a linear relationship between X and Y .
# Find if there is a relationship between sales(Y) and TV(X):
# Fit a simple linear regression model, with sales(Dependent) as the response and Tv as the predictor(Independent variable).
lm.fit = lm(sales~TV)
lm.fit
# Call:
# lm(formula = sales ~ TV)
# Coefficients:
# (Intercept)           TV
#     7.03259      0.04754
# The linear equation is: sales ~ 7.03259 + 0.04754 TV
# Visualisation of the regression:
ggplot(data, aes(x = TV, y = sales, colour = "red",)) +
geom_point() + stat_smooth(method = lm, colour = "blue", se = FALSE)+
ggtitle("Regression: TV vs SALES") + font("title", size = 20) +
ylab("Sales") + font("ylab", size = 15) +
xlab("TV Advertisement Budget(000)") + font("xlab", size = 15)
# _________________________________________________________
# MODEL ASSESMENT(Quality of the model)
# ________________________________________________________
summary(lm.fit)
# _________________________________________________________
# # 1. Is there a relationship between advertising sales and budget?
# From the F-statistic test, p-value is <2.2e-16 indicating a clear evidence of a relationship between TV advetisement budget and sales
# 2. How strong is the relationship?
#    Measures of Models of Accuracy:
#  a.RSE (Residual Standard Error)
# RSE is the residual variation
# RSE provides an absolute measure of patterns in the data that can't be explained by the model. The smaller the RSE, the better the model.
cat("RSE: ",sigma(lm.fit), "\n") # = 3.259
# Actual sales in each market deviate from the true regression line by approximately 3,259 units, on average.
# Prediction Error rate.
# It's a measure of how well the model predicts the response variable.
# It is found by dividing the RSE by the mean of sales: (RSE/mean(sales); (3259/14022)
cat("PE:",sigma(lm.fit)/mean(sales), "\n") # 23% error rate
# Percentage error indicated is 23%
#  b. R Squared
# For simple regression this is qual to square of pearson coefficient[cor(sales, TV)^2]
cat("R-squared: ",summary(lm.fit)$r.squared, "\n")  # = (cor(TV, sales))^2 = = 0.6118751
#  Approximately 61% of the variability in the response can be explained by the model
# 3. Does TV as a variable contribute to sales?(The significance of TV as a variable)
# This is done by assessing the Accuracy of the Coefficient Estimates(Coefficients significance) by
# Examine the p-values associated with the  TV predictor  t-statistic:
# Hypothesis:
#   H0 : ??1 = 0
#   Ha : ??1 != 0
summary(lm.fit)$coefficient
#             Estimate  Std. Error  t value Pr(>|t|)
# (Intercept) 7.032594   0.457843   15.36   <2e-16 ***
# TV          0.047537   0.002691   17.67   <2e-16 ***
#             p-value: < 2.2e-16
# p < 0.05 There is a significant association between TV and sales
# Both the p-values ( Pr(r|t|) ) for the intercept and the predictor variable are highly significant,
# Reject null hypothesis and accept the alternative hypothesis: There is a relationship existing between X and Y.
#  4. How large is the effect of TV Aadvertisement on sales?
# Confidence Interval for the model:
confint(lm.fit)
# That is, there is approximately a 95% chance that the interval [0.042, 0.053] will contain the true value of b1
# 5. Is the relationship linear?
# we saw that residual plots can be used in order to identify non-linearity.
data$predicted <- predict(lm.fit)
data$residuals <- residuals(lm.fit)
# Quick look
data %>% select(sales, predicted, residuals) %>% head()
# Plot the actual and predicted values
ggplot(data, aes(x = TV, y = sales)) +
geom_smooth(method = "lm", se = FALSE, color = "#00AFBB") +
geom_segment(aes(xend = TV, yend = predicted), alpha = .2)  +
geom_point(aes(color = residuals)) +
scale_color_gradient2(low = "blue", mid = "white", high = "red") +
guides(color = FALSE) +
geom_point(aes(y = predicted), shape = 1)
# The colours nicely help to identify non-linearity in the data.
# we can see that there is more red for extreme values of hp where the actual values are greater than what is being predicted.
# There is more blue in the centre, however, indicating that the actual values are less than what is being predicted.
# Together, this suggests that the relationship between the variables is non-linear, and might be better modelled by including a quadratic term in the regression equation.
